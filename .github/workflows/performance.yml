name: ðŸ“Š Performance Monitoring

on:
  schedule:
    # Run performance tests every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

env:
  NODE_VERSION: '18.x'

jobs:
  # ===============================================
  # âš¡ PERFORMANCE TESTING SUITE
  # ===============================================
  
  lighthouse-audit:
    name: ðŸ” Lighthouse Audit
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    strategy:
      matrix:
        url:
          - ${{ github.event.inputs.environment == 'staging' && 'https://staging.sovren.dev' || 'https://sovren.dev' }}
        device: ['desktop', 'mobile']
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: ðŸ” Run Lighthouse audit
        uses: treosh/lighthouse-ci-action@v10
        id: lighthouse
        with:
          urls: ${{ matrix.url }}
          configPath: './.lighthouserc.json'
          uploadArtifacts: true
          temporaryPublicStorage: true
          budgetPath: '.lighthouseBudget.json'
          runs: 3
      
      - name: ðŸ“Š Format Lighthouse results
        run: |
          echo "## ðŸ” Lighthouse Results - ${{ matrix.device }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**URL:** ${{ matrix.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Device:** ${{ matrix.device }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Core Web Vitals:**" >> $GITHUB_STEP_SUMMARY
          echo "- Performance: ${{ steps.lighthouse.outputs.scores.performance }}" >> $GITHUB_STEP_SUMMARY
          echo "- Accessibility: ${{ steps.lighthouse.outputs.scores.accessibility }}" >> $GITHUB_STEP_SUMMARY
          echo "- Best Practices: ${{ steps.lighthouse.outputs.scores.best-practices }}" >> $GITHUB_STEP_SUMMARY
          echo "- SEO: ${{ steps.lighthouse.outputs.scores.seo }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "[ðŸ“Š Full Report](${{ steps.lighthouse.outputs.links.report }})" >> $GITHUB_STEP_SUMMARY

  # ===============================================
  # ðŸ‹ï¸ LOAD TESTING
  # ===============================================
  
  load-testing:
    name: ðŸ‹ï¸ Load Testing
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“¦ Install K6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
      
      - name: ðŸ—ï¸ Create load test script
        run: |
          cat > load-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate, Trend } from 'k6/metrics';
          
          export let errorRate = new Rate('errors');
          export let responseTime = new Trend('response_time');
          
          export let options = {
            stages: [
              { duration: '2m', target: 10 },
              { duration: '5m', target: 10 },
              { duration: '2m', target: 20 },
              { duration: '5m', target: 20 },
              { duration: '2m', target: 0 },
            ],
            thresholds: {
              errors: ['rate<0.1'],
              response_time: ['p(95)<500'],
              http_req_duration: ['p(99)<1000'],
            },
          };
          
          const BASE_URL = '${{ github.event.inputs.environment == 'staging' && 'https://staging.sovren.dev' || 'https://sovren.dev' }}';
          
          export default function () {
            let responses = http.batch([
              ['GET', `${BASE_URL}/`],
              ['GET', `${BASE_URL}/api/v1/health`],
              ['GET', `${BASE_URL}/api/v1/feature-flags`],
            ]);
            
            responses.forEach((response) => {
              check(response, {
                'status is 200': (r) => r.status === 200,
                'response time < 500ms': (r) => r.timings.duration < 500,
              }) || errorRate.add(1);
              
              responseTime.add(response.timings.duration);
            });
            
            sleep(1);
          }
          EOF
      
      - name: ðŸ‹ï¸ Run load test
        run: |
          k6 run --out json=load-test-results.json load-test.js
          echo "## ðŸ‹ï¸ Load Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Target:** ${{ github.event.inputs.environment == 'staging' && 'https://staging.sovren.dev' || 'https://sovren.dev' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Duration:** 16 minutes" >> $GITHUB_STEP_SUMMARY
          echo "**Max VUs:** 20" >> $GITHUB_STEP_SUMMARY
      
      - name: ðŸ“Š Process load test results
        run: |
          # Parse and display key metrics from the JSON output
          if [ -f load-test-results.json ]; then
            echo "Load test completed successfully" >> $GITHUB_STEP_SUMMARY
            echo "Results saved to artifacts" >> $GITHUB_STEP_SUMMARY
          else
            echo "Load test failed to generate results" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
      
      - name: ðŸ“¤ Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: load-test-results.json

  # ===============================================
  # ðŸ“¦ BUNDLE SIZE MONITORING
  # ===============================================
  
  bundle-analysis:
    name: ðŸ“¦ Bundle Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit
      
      - name: ðŸ—ï¸ Build application
        run: npm run build
      
      - name: ðŸ“Š Analyze bundle size
        run: |
          cd packages/frontend
          
          # Get bundle sizes
          MAIN_JS_SIZE=$(du -h dist/assets/*.js | sort -hr | head -1 | cut -f1)
          MAIN_CSS_SIZE=$(du -h dist/assets/*.css | sort -hr | head -1 | cut -f1)
          TOTAL_SIZE=$(du -sh dist | cut -f1)
          
          echo "## ðŸ“¦ Bundle Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Bundle Sizes:**" >> $GITHUB_STEP_SUMMARY
          echo "- Main JS: $MAIN_JS_SIZE" >> $GITHUB_STEP_SUMMARY
          echo "- Main CSS: $MAIN_CSS_SIZE" >> $GITHUB_STEP_SUMMARY
          echo "- Total: $TOTAL_SIZE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check if bundles exceed thresholds
          JS_SIZE_BYTES=$(stat -c%s dist/assets/*.js | sort -nr | head -1)
          if [ $JS_SIZE_BYTES -gt 250000 ]; then
            echo "âš ï¸ **Warning:** Main JS bundle exceeds 250KB" >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ… Main JS bundle size is within limits" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: ðŸ“Š Generate bundle report
        run: |
          cd packages/frontend
          npx webpack-bundle-analyzer dist/assets/*.js --report bundle-report.html --mode static --no-open
          echo "Bundle analysis report generated" >> $GITHUB_STEP_SUMMARY
      
      - name: ðŸ“¤ Upload bundle report
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: packages/frontend/bundle-report.html

  # ===============================================
  # ðŸ” ACCESSIBILITY TESTING
  # ===============================================
  
  accessibility-testing:
    name: â™¿ Accessibility Testing
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
      
      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“¦ Install Pa11y
        run: npm install -g pa11y pa11y-ci
      
      - name: â™¿ Run accessibility tests
        run: |
          TARGET_URL="${{ github.event.inputs.environment == 'staging' && 'https://staging.sovren.dev' || 'https://sovren.dev' }}"
          
          echo "## â™¿ Accessibility Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Target:** $TARGET_URL" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Run Pa11y tests
          if pa11y $TARGET_URL --reporter json > accessibility-results.json; then
            echo "âœ… No accessibility issues found" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Accessibility issues detected - see artifacts" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: ðŸ“¤ Upload accessibility results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-results
          path: accessibility-results.json

  # ===============================================
  # ðŸ“ˆ MONITORING SUMMARY
  # ===============================================
  
  monitoring-summary:
    name: ðŸ“ˆ Monitoring Summary
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, load-testing, bundle-analysis, accessibility-testing]
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: ðŸ“Š Create monitoring summary
        run: |
          echo "## ðŸ“ˆ Performance Monitoring Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ github.event.inputs.environment || 'production' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Results:**" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ” Lighthouse: ${{ needs.lighthouse-audit.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ‹ï¸ Load Testing: ${{ needs.load-testing.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¦ Bundle Analysis: ${{ needs.bundle-analysis.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- â™¿ Accessibility: ${{ needs.accessibility-testing.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall health check
          if [[ "${{ needs.lighthouse-audit.result }}" == "success" && 
                "${{ needs.load-testing.result }}" == "success" && 
                "${{ needs.bundle-analysis.result }}" == "success" && 
                "${{ needs.accessibility-testing.result }}" == "success" ]]; then
            echo "ðŸŽ‰ **Overall Status:** All performance tests passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Overall Status:** Some performance issues detected" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: ðŸ“¢ Performance notification
        uses: 8398a7/action-slack@v3
        if: failure()
        with:
          status: failure
          text: |
            ðŸ“Š Performance monitoring detected issues!
            
            ðŸŽ¯ Environment: ${{ github.event.inputs.environment || 'production' }}
            ðŸ“… Date: $(date)
            ðŸ”— Check GitHub Actions for details
          webhook_url: ${{ secrets.SLACK_WEBHOOK }} 
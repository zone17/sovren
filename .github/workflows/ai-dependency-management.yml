name: 🤖 AI Dependency Management

on:
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Type of updates to perform'
        required: true
        default: 'security'
        type: choice
        options:
          - security     # Only security updates
          - minor        # Minor version updates
          - major        # Major version updates
          - ai-curated   # AI decides what to update

env:
  NODE_VERSION: '18.x'
  PYTHON_VERSION: '3.11'
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

jobs:
  # ===============================================
  # 🔍 AI-POWERED DEPENDENCY ANALYSIS
  # ===============================================

  ai-dependency-analysis:
    name: 🔍 AI Dependency Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20

    outputs:
      security-updates: ${{ steps.analysis.outputs.security-updates }}
      recommended-updates: ${{ steps.analysis.outputs.recommended-updates }}
      risk-assessment: ${{ steps.analysis.outputs.risk-assessment }}
      compatibility-score: ${{ steps.analysis.outputs.compatibility-score }}

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 🐍 Setup Python for AI analysis
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install analysis tools
        run: |
          npm install -g npm-check-updates audit-ci snyk
          pip install openai numpy pandas requests packaging semver

      - name: 🔍 Comprehensive Dependency Audit
        run: |
          echo "## 🔍 Dependency Audit Results" > dependency-audit.md

          # NPM Security Audit
          echo "### Security Vulnerabilities" >> dependency-audit.md
          npm audit --json > npm-audit.json || true
          cat npm-audit.json | jq -r '.vulnerabilities | to_entries[] | "- **\(.key)**: \(.value.severity) - \(.value.title)"' >> dependency-audit.md || echo "- No vulnerabilities found" >> dependency-audit.md

          # Outdated packages
          echo "### Outdated Packages" >> dependency-audit.md
          npm outdated --json > outdated.json || true

          # Snyk scan
          echo "### Snyk Security Scan" >> dependency-audit.md
          snyk test --json > snyk-results.json || true

          echo "Audit completed - files generated for AI analysis"

      - name: 🤖 AI Dependency Intelligence
        id: analysis
        run: |
          cat > ai_dependency_analyzer.py << 'EOF'
          import openai
          import json
          import os
          import subprocess
          import requests
          from packaging import version
          from datetime import datetime, timedelta

          class AIDependencyAnalyzer:
              def __init__(self):
                  openai.api_key = os.getenv('OPENAI_API_KEY')
                  self.package_json = self.load_package_json()
                  self.audit_data = self.load_audit_data()
                  self.outdated_data = self.load_outdated_data()
                  self.update_type = os.getenv('UPDATE_TYPE', 'security')

              def load_package_json(self):
                  try:
                      with open('package.json', 'r') as f:
                          return json.load(f)
                  except:
                      return {}

              def load_audit_data(self):
                  try:
                      with open('npm-audit.json', 'r') as f:
                          return json.load(f)
                  except:
                      return {}

              def load_outdated_data(self):
                  try:
                      with open('outdated.json', 'r') as f:
                          return json.load(f)
                  except:
                      return {}

              def get_package_popularity(self, package_name):
                  """Get package download stats from npm"""
                  try:
                      response = requests.get(f"https://api.npmjs.org/downloads/point/last-month/{package_name}")
                      if response.status_code == 200:
                          data = response.json()
                          return data.get('downloads', 0)
                  except:
                      pass
                  return 0

              def get_package_info(self, package_name):
                  """Get detailed package information"""
                  try:
                      response = requests.get(f"https://registry.npmjs.org/{package_name}")
                      if response.status_code == 200:
                          data = response.json()
                          latest_version = data.get('dist-tags', {}).get('latest', '')
                          description = data.get('description', '')
                          homepage = data.get('homepage', '')
                          repository = data.get('repository', {})

                          return {
                              'latest_version': latest_version,
                              'description': description,
                              'homepage': homepage,
                              'repository': repository.get('url', '') if isinstance(repository, dict) else str(repository),
                              'weekly_downloads': self.get_package_popularity(package_name)
                          }
                  except:
                      pass
                  return {}

              def analyze_security_updates(self):
                  """Analyze security vulnerabilities and recommend fixes"""
                  security_updates = []

                  vulnerabilities = self.audit_data.get('vulnerabilities', {})
                  for package, vuln_data in vulnerabilities.items():
                      severity = vuln_data.get('severity', 'unknown')
                      if severity in ['high', 'critical']:
                          security_updates.append({
                              'package': package,
                              'severity': severity,
                              'title': vuln_data.get('title', ''),
                              'priority': 'immediate' if severity == 'critical' else 'high'
                          })

                  return security_updates

              def ai_package_risk_assessment(self, package_name, current_version, latest_version):
                  """Use AI to assess upgrade risk"""
                  if not openai.api_key:
                      return {"risk": "medium", "reasoning": "AI analysis disabled"}

                  package_info = self.get_package_info(package_name)

                  try:
                      prompt = f"""
                      Assess the risk of upgrading this npm package:

                      Package: {package_name}
                      Current Version: {current_version}
                      Latest Version: {latest_version}
                      Weekly Downloads: {package_info.get('weekly_downloads', 'unknown')}
                      Description: {package_info.get('description', 'N/A')[:200]}

                      Consider:
                      1. Version difference (major/minor/patch)
                      2. Package popularity and stability
                      3. Breaking changes potential
                      4. Security implications
                      5. Maintenance status

                      Respond with JSON: {{"risk": "low|medium|high", "reasoning": "brief explanation", "recommendation": "action to take"}}
                      """

                      response = openai.ChatCompletion.create(
                          model="gpt-4",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=300,
                          temperature=0.3
                      )

                      return json.loads(response.choices[0].message.content)
                  except Exception as e:
                      return {"risk": "medium", "reasoning": f"AI analysis failed: {e}"}

              def intelligent_update_selection(self):
                  """AI-driven package update selection"""
                  recommended_updates = []

                  for package, details in self.outdated_data.items():
                      current = details.get('current', '')
                      latest = details.get('latest', '')
                      wanted = details.get('wanted', '')

                      if not current or not latest:
                          continue

                      # Skip if already at latest
                      if current == latest:
                          continue

                      # AI risk assessment
                      risk_assessment = self.ai_package_risk_assessment(package, current, latest)

                      # Decision logic based on update type
                      should_update = False
                      update_to = latest

                      if self.update_type == 'security':
                          # Only update if security issue
                          should_update = any(pkg['package'] == package for pkg in self.analyze_security_updates())

                      elif self.update_type == 'minor':
                          # Update minor/patch versions if low-medium risk
                          try:
                              current_ver = version.parse(current)
                              latest_ver = version.parse(latest)
                              if latest_ver.major == current_ver.major and risk_assessment['risk'] in ['low', 'medium']:
                                  should_update = True
                          except:
                              pass

                      elif self.update_type == 'major':
                          # Update major versions if low risk
                          should_update = risk_assessment['risk'] == 'low'

                      elif self.update_type == 'ai-curated':
                          # AI decides based on comprehensive analysis
                          should_update = risk_assessment['risk'] == 'low' or (
                              risk_assessment['risk'] == 'medium' and
                              'security' in risk_assessment.get('reasoning', '').lower()
                          )

                      if should_update:
                          recommended_updates.append({
                              'package': package,
                              'current_version': current,
                              'target_version': update_to,
                              'risk_level': risk_assessment['risk'],
                              'reasoning': risk_assessment['reasoning'],
                              'recommendation': risk_assessment.get('recommendation', 'Update recommended')
                          })

                  return recommended_updates

              def calculate_compatibility_score(self, updates):
                  """Calculate overall compatibility score for proposed updates"""
                  if not updates:
                      return 100

                  risk_weights = {'low': 10, 'medium': 30, 'high': 60}
                  total_risk = sum(risk_weights.get(update['risk_level'], 30) for update in updates)
                  max_possible_risk = len(updates) * 60

                  compatibility_score = max(0, 100 - (total_risk / max_possible_risk * 100))
                  return round(compatibility_score, 1)

              def generate_analysis_report(self):
                  """Generate comprehensive analysis report"""
                  security_updates = self.analyze_security_updates()
                  recommended_updates = self.intelligent_update_selection()
                  compatibility_score = self.calculate_compatibility_score(recommended_updates)

                  risk_assessment = {
                      'total_vulnerabilities': len(security_updates),
                      'critical_vulnerabilities': len([u for u in security_updates if u['severity'] == 'critical']),
                      'recommended_updates': len(recommended_updates),
                      'high_risk_updates': len([u for u in recommended_updates if u['risk_level'] == 'high']),
                      'overall_risk': 'high' if any(u['severity'] == 'critical' for u in security_updates) else 'medium' if security_updates else 'low'
                  }

                  return {
                      'security_updates': security_updates,
                      'recommended_updates': recommended_updates,
                      'risk_assessment': risk_assessment,
                      'compatibility_score': compatibility_score
                  }

          if __name__ == "__main__":
              analyzer = AIDependencyAnalyzer()
              analysis = analyzer.generate_analysis_report()

              # Output for GitHub Actions
              print(f"security-updates={json.dumps(analysis['security_updates'])}")
              print(f"recommended-updates={json.dumps(analysis['recommended_updates'])}")
              print(f"risk-assessment={json.dumps(analysis['risk_assessment'])}")
              print(f"compatibility-score={analysis['compatibility_score']}")

              # Save detailed report
              with open('ai-dependency-analysis.json', 'w') as f:
                  json.dump(analysis, f, indent=2)
          EOF

          python ai_dependency_analyzer.py > analysis_output.txt

          # Parse outputs for GitHub Actions
          echo "security-updates=$(grep 'security-updates=' analysis_output.txt | cut -d'=' -f2-)" >> $GITHUB_OUTPUT
          echo "recommended-updates=$(grep 'recommended-updates=' analysis_output.txt | cut -d'=' -f2-)" >> $GITHUB_OUTPUT
          echo "risk-assessment=$(grep 'risk-assessment=' analysis_output.txt | cut -d'=' -f2-)" >> $GITHUB_OUTPUT
          echo "compatibility-score=$(grep 'compatibility-score=' analysis_output.txt | cut -d'=' -f2)" >> $GITHUB_OUTPUT
        env:
          UPDATE_TYPE: ${{ github.event.inputs.update_type || 'security' }}

      - name: 📊 Generate Analysis Summary
        run: |
          echo "## 🤖 AI Dependency Analysis Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Update Type:** ${{ github.event.inputs.update_type || 'security' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Compatibility Score:** ${{ steps.analysis.outputs.compatibility-score }}/100" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          SECURITY_COUNT=$(echo '${{ steps.analysis.outputs.security-updates }}' | jq length)
          RECOMMENDED_COUNT=$(echo '${{ steps.analysis.outputs.recommended-updates }}' | jq length)

          echo "**Security Updates:** $SECURITY_COUNT packages" >> $GITHUB_STEP_SUMMARY
          echo "**Recommended Updates:** $RECOMMENDED_COUNT packages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📄 Full analysis available in artifacts" >> $GITHUB_STEP_SUMMARY

      - name: 📤 Upload Analysis Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dependency-analysis
          path: |
            ai-dependency-analysis.json
            dependency-audit.md
            npm-audit.json
            outdated.json
            snyk-results.json

  # ===============================================
  # 🔄 AUTOMATED DEPENDENCY UPDATES
  # ===============================================

  automated-updates:
    name: 🔄 Automated Updates
    runs-on: ubuntu-latest
    needs: ai-dependency-analysis
    timeout-minutes: 30
    if: fromJSON(needs.ai-dependency-analysis.outputs.compatibility-score) >= 70

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: 📥 Download analysis results
        uses: actions/download-artifact@v4
        with:
          name: dependency-analysis

      - name: 🔄 Apply AI-Recommended Updates
        run: |
          cat > apply_updates.py << 'EOF'
          import json
          import subprocess
          import os

          class DependencyUpdater:
              def __init__(self):
                  with open('ai-dependency-analysis.json', 'r') as f:
                      self.analysis = json.load(f)
                  self.updated_packages = []
                  self.failed_updates = []

              def apply_security_updates(self):
                  """Apply critical security updates first"""
                  security_updates = self.analysis['security_updates']

                  for update in security_updates:
                      if update['priority'] == 'immediate':
                          try:
                              result = subprocess.run(
                                  ['npm', 'audit', 'fix', '--force'],
                                  capture_output=True, text=True, check=True
                              )
                              self.updated_packages.append(f"Security fix: {update['package']}")
                          except subprocess.CalledProcessError as e:
                              self.failed_updates.append(f"Failed security fix: {update['package']} - {e}")

              def apply_recommended_updates(self):
                  """Apply AI-recommended updates"""
                  recommended = self.analysis['recommended_updates']

                  for update in recommended:
                      package = update['package']
                      target_version = update['target_version']
                      risk_level = update['risk_level']

                      # Skip high-risk updates in automated mode
                      if risk_level == 'high':
                          continue

                      try:
                          # Update specific package to target version
                          cmd = ['npm', 'install', f"{package}@{target_version}"]
                          result = subprocess.run(cmd, capture_output=True, text=True, check=True)

                          self.updated_packages.append(f"{package}: {update['current_version']} → {target_version} (Risk: {risk_level})")
                      except subprocess.CalledProcessError as e:
                          self.failed_updates.append(f"{package}: Update failed - {e}")

              def verify_updates(self):
                  """Verify that updates don't break basic functionality"""
                  try:
                      # Install dependencies
                      subprocess.run(['npm', 'ci'], check=True, capture_output=True)

                      # Run basic tests
                      subprocess.run(['npm', 'run', 'build'], check=True, capture_output=True)

                      return True, "Build successful after updates"
                  except subprocess.CalledProcessError as e:
                      return False, f"Build failed after updates: {e}"

              def generate_update_report(self):
                  """Generate update report"""
                  verification_passed, verification_msg = self.verify_updates()

                  report = {
                      'updated_packages': self.updated_packages,
                      'failed_updates': self.failed_updates,
                      'verification_passed': verification_passed,
                      'verification_message': verification_msg,
                      'total_updates': len(self.updated_packages),
                      'total_failures': len(self.failed_updates)
                  }

                  return report

          if __name__ == "__main__":
              updater = DependencyUpdater()

              # Apply updates in order of priority
              updater.apply_security_updates()
              updater.apply_recommended_updates()

              # Generate report
              report = updater.generate_update_report()

              print(f"UPDATED_PACKAGES={len(report['updated_packages'])}")
              print(f"FAILED_UPDATES={len(report['failed_updates'])}")
              print(f"VERIFICATION_PASSED={report['verification_passed']}")

              # Save report
              with open('update-report.json', 'w') as f:
                  json.dump(report, f, indent=2)

              # Create summary for GitHub
              with open('update-summary.md', 'w') as f:
                  f.write("# 🔄 Automated Dependency Updates\n\n")
                  f.write(f"**Total Updates Applied:** {report['total_updates']}\n")
                  f.write(f"**Failed Updates:** {report['total_failures']}\n")
                  f.write(f"**Build Verification:** {'✅ Passed' if report['verification_passed'] else '❌ Failed'}\n\n")

                  if report['updated_packages']:
                      f.write("## ✅ Successfully Updated\n")
                      for pkg in report['updated_packages']:
                          f.write(f"- {pkg}\n")
                      f.write("\n")

                  if report['failed_updates']:
                      f.write("## ❌ Failed Updates\n")
                      for pkg in report['failed_updates']:
                          f.write(f"- {pkg}\n")
                      f.write("\n")

                  f.write(f"## 🔍 Verification\n{report['verification_message']}\n")
          EOF

          python apply_updates.py > update_output.txt

          echo "UPDATED_COUNT=$(grep 'UPDATED_PACKAGES=' update_output.txt | cut -d'=' -f2)" >> $GITHUB_ENV
          echo "FAILED_COUNT=$(grep 'FAILED_UPDATES=' update_output.txt | cut -d'=' -f2)" >> $GITHUB_ENV
          echo "VERIFICATION=$(grep 'VERIFICATION_PASSED=' update_output.txt | cut -d'=' -f2)" >> $GITHUB_ENV

      - name: 🧪 Run Comprehensive Tests
        if: env.VERIFICATION == 'True'
        run: |
          echo "🧪 Running comprehensive test suite after updates..."

          # Run different test suites
          npm run lint || echo "Lint warnings detected"
          npm run type-check
          npm run test:ci

          echo "✅ All tests passed after dependency updates" >> $GITHUB_STEP_SUMMARY

      - name: 📝 Create Pull Request
        if: env.UPDATED_COUNT != '0' && env.VERIFICATION == 'True'
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: |
            🤖 AI-Curated Dependency Updates

            - Updated ${{ env.UPDATED_COUNT }} packages
            - AI risk assessment passed
            - Build verification successful
            - All tests passing
          title: '🤖 AI-Curated Dependency Updates'
          body-path: update-summary.md
          branch: ai-dependency-updates
          delete-branch: true
          labels: |
            dependencies
            ai-automated
            security

      - name: 📊 Update Summary
        run: |
          echo "## 🔄 Dependency Update Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Packages Updated:** ${{ env.UPDATED_COUNT }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed Updates:** ${{ env.FAILED_COUNT }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Build Verification:** ${{ env.VERIFICATION == 'True' && '✅ Passed' || '❌ Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Compatibility Score:** ${{ needs.ai-dependency-analysis.outputs.compatibility-score }}/100" >> $GITHUB_STEP_SUMMARY

      - name: 📤 Upload Update Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dependency-updates
          path: |
            update-report.json
            update-summary.md
            package.json
            package-lock.json

  # ===============================================
  # 🚨 CRITICAL SECURITY RESPONSE
  # ===============================================

  emergency-security-response:
    name: 🚨 Emergency Security Response
    runs-on: ubuntu-latest
    needs: ai-dependency-analysis
    timeout-minutes: 15
    if: fromJSON(needs.ai-dependency-analysis.outputs.risk-assessment).critical_vulnerabilities > 0

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 🚨 Emergency Security Fixes
        run: |
          echo "🚨 CRITICAL SECURITY VULNERABILITIES DETECTED"
          echo "Applying emergency security fixes..."

          # Force security fixes
          npm audit fix --force || echo "Some fixes may require manual intervention"

          # Verify build still works
          npm run build || echo "Build may need attention after security fixes"

          echo "## 🚨 Emergency Security Response" >> $GITHUB_STEP_SUMMARY
          echo "Critical vulnerabilities detected and automatic fixes applied." >> $GITHUB_STEP_SUMMARY
          echo "**Action Required:** Review the emergency security PR immediately." >> $GITHUB_STEP_SUMMARY

      - name: 📝 Create Emergency PR
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: |
            🚨 EMERGENCY: Critical Security Fixes

            Critical vulnerabilities detected by AI analysis.
            Automatic security fixes applied.

            REQUIRES IMMEDIATE REVIEW AND MERGE.
          title: '🚨 EMERGENCY: Critical Security Vulnerabilities'
          body: |
            # 🚨 EMERGENCY SECURITY RESPONSE

            **Critical security vulnerabilities detected by AI analysis.**

            ## ⚡ Immediate Actions Taken
            - Automatic security fixes applied via `npm audit fix --force`
            - Build verification attempted

            ## 🔍 Vulnerabilities Found
            ${{ needs.ai-dependency-analysis.outputs.security-updates }}

            ## ⚠️ REQUIRED ACTIONS
            1. **MERGE THIS PR IMMEDIATELY** after review
            2. Deploy to production as soon as possible
            3. Monitor application for any issues
            4. Review security scan results in artifacts

            ---
            *This is an automated emergency response triggered by AI security analysis.*
          branch: emergency-security-fixes
          delete-branch: true
          labels: |
            critical
            security
            emergency
            ai-automated

      - name: 🔔 Emergency Notifications
        run: |
          # Slack notification for critical security issues
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"🚨 CRITICAL SECURITY ALERT: Emergency security fixes applied to Sovren. Review and merge PR immediately!"}' \
            ${{ secrets.SLACK_WEBHOOK || 'https://hooks.slack.com/dummy' }}

          # Could also integrate with PagerDuty, email, etc.
          echo "Emergency notifications sent"

  # ===============================================
  # 📊 DEPENDENCY HEALTH MONITORING
  # ===============================================

  dependency-health-monitoring:
    name: 📊 Dependency Health Monitoring
    runs-on: ubuntu-latest
    needs: ai-dependency-analysis
    timeout-minutes: 10

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 📊 Generate Health Dashboard
        run: |
          cat > dependency_health_dashboard.py << 'EOF'
          import json
          import os
          from datetime import datetime

          class DependencyHealthDashboard:
              def __init__(self):
                  # Load analysis results if available
                  self.analysis = {}
                  if os.path.exists('ai-dependency-analysis.json'):
                      with open('ai-dependency-analysis.json', 'r') as f:
                          self.analysis = json.load(f)

              def generate_health_metrics(self):
                  """Generate dependency health metrics"""
                  risk_assessment = self.analysis.get('risk_assessment', {})
                  compatibility_score = self.analysis.get('compatibility_score', 100)

                  # Calculate health score
                  security_score = 100 - (risk_assessment.get('total_vulnerabilities', 0) * 10)
                  freshness_score = 100 - (risk_assessment.get('recommended_updates', 0) * 2)

                  overall_health = (security_score + freshness_score + compatibility_score) / 3

                  return {
                      'overall_health': round(overall_health, 1),
                      'security_score': max(0, security_score),
                      'freshness_score': max(0, freshness_score),
                      'compatibility_score': compatibility_score,
                      'last_updated': datetime.now().isoformat(),
                      'status': 'excellent' if overall_health >= 90 else
                               'good' if overall_health >= 75 else
                               'needs_attention' if overall_health >= 60 else 'critical'
                  }

              def create_dashboard_html(self, metrics):
                  """Create HTML dashboard"""
                  html = f"""
                  <!DOCTYPE html>
                  <html>
                  <head>
                      <title>Sovren Dependency Health Dashboard</title>
                      <style>
                          body {{ font-family: Arial, sans-serif; margin: 20px; }}
                          .metric {{ padding: 10px; margin: 10px; border-radius: 5px; }}
                          .excellent {{ background-color: #d4edda; }}
                          .good {{ background-color: #fff3cd; }}
                          .needs_attention {{ background-color: #f8d7da; }}
                          .critical {{ background-color: #f5c6cb; }}
                          .score {{ font-size: 2em; font-weight: bold; }}
                      </style>
                  </head>
                  <body>
                      <h1>🏥 Dependency Health Dashboard</h1>
                      <div class="metric {metrics['status']}">
                          <h2>Overall Health Score</h2>
                          <div class="score">{metrics['overall_health']}/100</div>
                          <p>Status: {metrics['status'].replace('_', ' ').title()}</p>
                      </div>

                      <div class="metric">
                          <h3>Security Score: {metrics['security_score']}/100</h3>
                      </div>

                      <div class="metric">
                          <h3>Freshness Score: {metrics['freshness_score']}/100</h3>
                      </div>

                      <div class="metric">
                          <h3>Compatibility Score: {metrics['compatibility_score']}/100</h3>
                      </div>

                      <p><em>Last Updated: {metrics['last_updated']}</em></p>
                  </body>
                  </html>
                  """
                  return html

          if __name__ == "__main__":
              dashboard = DependencyHealthDashboard()
              metrics = dashboard.generate_health_metrics()

              # Create HTML dashboard
              html = dashboard.create_dashboard_html(metrics)
              with open('dependency-health-dashboard.html', 'w') as f:
                  f.write(html)

              # Output metrics
              print(f"HEALTH_SCORE={metrics['overall_health']}")
              print(f"STATUS={metrics['status']}")

              # Save metrics
              with open('health-metrics.json', 'w') as f:
                  json.dump(metrics, f, indent=2)
          EOF

          python dependency_health_dashboard.py > health_output.txt

          echo "HEALTH_SCORE=$(grep 'HEALTH_SCORE=' health_output.txt | cut -d'=' -f2)" >> $GITHUB_ENV
          echo "HEALTH_STATUS=$(grep 'STATUS=' health_output.txt | cut -d'=' -f2)" >> $GITHUB_ENV

      - name: 📊 Health Summary
        run: |
          echo "## 🏥 Dependency Health Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Health Score:** ${{ env.HEALTH_SCORE }}/100" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ env.HEALTH_STATUS }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 [View Full Dashboard](./dependency-health-dashboard.html)" >> $GITHUB_STEP_SUMMARY

      - name: 📤 Upload Health Dashboard
        uses: actions/upload-artifact@v4
        with:
          name: dependency-health-dashboard
          path: |
            dependency-health-dashboard.html
            health-metrics.json
